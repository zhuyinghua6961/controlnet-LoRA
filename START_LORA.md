# ğŸ§© LoRA å…¨æµç¨‹æŒ‡å—ï¼ˆControlNet â†’ UNet LoRA â†’ æ¨ç†ï¼‰

æœ¬æŒ‡å—åœ¨â€œå·²å®Œæˆ ControlNet è®­ç»ƒå¹¶å…·å¤‡è¾ƒé«˜ä½ç½®ç²¾åº¦â€çš„å‰æä¸‹ï¼Œé€šè¿‡ç»™ UNet æ³¨å…¥ LoRA æ¥æå‡ç”»è´¨ï¼ˆé”åº¦ã€å¯¹æ¯”åº¦ã€é¢œè‰²ç¨³å®šï¼‰ã€‚

---

## 0. ç¯å¢ƒä¸ä¾èµ–

```bash
pip install -r requirements.txt
```

è¦æ±‚ï¼šPython 3.8+ã€CUDA 11.7+ã€æ˜¾å­˜â‰¥12GBï¼ˆæ¨è24GBï¼‰ã€‚

---

## 1. é˜¶æ®µä¸€ï¼šè®­ç»ƒ ControlNetï¼ˆè‹¥å·²è®­ç»ƒå¯è·³è¿‡ï¼‰

ä½¿ç”¨ä½ ç°æœ‰çš„é…ç½®ï¼š
```bash
python train_controlnet_fixed.py --config config.yaml --from_scratch
# è®­ç»ƒè¾“å‡ºæœ€ç»ˆåœ¨: output/controlnet/controlnet/
```

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šåœ¨ `output/controlnet/` äº§ç”Ÿ checkpoint ä¸æ—¥å¿—ã€‚

---

## 2. é˜¶æ®µäºŒï¼šè®­ç»ƒ UNet LoRAï¼ˆä»…è®­ç»ƒ LoRAï¼Œå†»ç»“ ControlNet/UNetä¸»å¹²/VAE/TextEncoderï¼‰

ç¤ºä¾‹é…ç½®ï¼š`config_lora.yaml`
```yaml
project:
  name: "radar_controlnet_lora"
  output_dir: "output/controlnet_lora"

data:
  data_dir: "dataset"
  resolution: 512
  range_max: 200
  vel_max: 40

training:
  train_batch_size: 2
  gradient_accumulation_steps: 4
  num_train_epochs: 5
  learning_rate: 5.0e-5
  lr_scheduler: "cosine"
  lr_warmup_steps: 500
  max_grad_norm: 1.0
  save_steps: 2000
  mixed_precision: "fp16"
  dataloader_num_workers: 4

  # LoRA & loss
  lora_rank: 16
  heatmap_sigma: 8.0
  loss_weight_factor: 30.0
  use_focal_loss: false

controlnet:
  path: "output/controlnet/controlnet"  # å·²è®­ç»ƒå¥½çš„ ControlNet
```

å¯åŠ¨è®­ç»ƒï¼š
```bash
python train_controlnet_lora.py --config config_lora.yaml
# LoRA æœ€ç»ˆæƒé‡åœ¨: output/controlnet_lora/lora/
```

å»ºè®®è¶…å‚ï¼š
- lora_rank: 8â€“16ï¼›learning_rate: 5e-5 ~ 1e-4ï¼›warmup: 500 stepsï¼›epochs: 3â€“10
- heatmap_sigma å»ºè®®ä¸æ¨ç†ä¸€è‡´ï¼ˆå¦‚ 8.0ï¼‰
- loss_weight_factor å– 20â€“40 æ›´æ¸©å’Œï¼Œå‡å°‘ç³ŠåŒ–

---

## 2.5 ä¸¤é˜¶æ®µ + è½»è”åˆè®­ç»ƒï¼ˆæ¨èè¿›é˜¶ï¼‰

å½“ä½ å¸Œæœ›åœ¨å®šä½å·²ç¨³å®šçš„å‰æä¸‹è¿›ä¸€æ­¥å¢å¼ºç”»è´¨ï¼Œå¯ä½¿ç”¨â€œä¸¤é˜¶æ®µ+è½»è”åˆâ€è„šæœ¬ï¼š

```bash
python train_joint_lora_controlnet.py --config config_joint.yaml
# æœ€ç»ˆä¿å­˜ï¼šoutput/joint_lora_cn/final/controlnet/ ä¸ output/joint_lora_cn/final/lora/
```

é…ç½®ç¤ºä¾‹ï¼š`config_joint.yaml`ï¼ˆåŒ…å« stage1/2ï¼‰
- é˜¶æ®µ1ï¼šä»…è®­ ControlNetï¼ˆå®šä½ä¼˜å…ˆï¼‰ï¼Œå¦‚ `loss_weight_factor: 100`, `heatmap_sigma: 8.0`
- é˜¶æ®µ2ï¼šControlNet + UNet LoRA è”åˆï¼ˆå° lr å¾®è°ƒç”»è´¨ï¼‰ï¼Œå¦‚ `lora_learning_rate: 5e-5`, `loss_weight_factor: 60`

å»ºè®®ï¼š
- æ•°æ®é‡ 3000â€“4000 å¼ æ—¶ï¼Œé˜¶æ®µ1 40â€“80 epochï¼ˆæˆ–æŒ‰ä½ ç»éªŒ 80â€“100 æ›´ç¨³ï¼Œé…åˆæ—©åœï¼‰ï¼›é˜¶æ®µ2 3â€“10 epochï¼ˆå¯æŒ‰éœ€è¿½åŠ ï¼‰

---

## 3. æ¨ç†ï¼ˆæ”¯æŒæ˜¯å¦åŠ è½½ LoRAï¼‰

è„šæœ¬ï¼š`inference_lora.py`

ä»…ç”¨ ControlNetï¼š
```bash
python inference_lora.py \
  --controlnet_path output/controlnet/controlnet \
  --prompt_file test_prompt_example.txt \
  --output_dir results_cn \
  --config config.yaml \
  --lora_dir "" \
  --steps 40 --cfg 4.0 --controlnet_scale 1.2
```

ControlNet + LoRAï¼ˆæ¨èï¼‰ï¼š
```bash
python inference_lora.py \
  --controlnet_path output/controlnet/controlnet \
  --prompt_file test_prompt_example.txt \
  --output_dir results_cn_lora \
  --config config.yaml \
  --lora_dir output/controlnet_lora/lora \
  --lora_scale 0.7 \
  --steps 40 --cfg 4.0 --controlnet_scale 1.2
```

æç¤ºï¼š`lora_scale` è¿‡å¤§ä¼šå½±å“ç»“æ„ç»†èŠ‚ï¼Œå»ºè®® 0.6â€“0.8 åŒºé—´å¾®è°ƒã€‚

---

## 4. ä¸€é”®å…¨æµç¨‹ï¼ˆå…ˆ ControlNet â†’ å† LoRAï¼‰

è„šæœ¬ï¼š`train_full_pipeline.py`
```bash
python train_full_pipeline.py \
  --controlnet_config config.yaml \
  --lora_config config_lora.yaml

# å¼ºåˆ¶ ControlNet ä»å¤´
python train_full_pipeline.py --controlnet_config config.yaml --lora_config config_lora.yaml --from_scratch
```

è¯¥è„šæœ¬ä¼šï¼š
1) è¿è¡Œ ControlNet è®­ç»ƒï¼Œäº§å‡º `output/controlnet/controlnet/`
2) è‡ªåŠ¨æŠŠè·¯å¾„å†™å…¥ LoRA é…ç½®å‰¯æœ¬ `config_lora_autofilled.yaml`
3) ç»§ç»­è¿è¡Œ LoRA è®­ç»ƒï¼Œäº§å‡º `output/controlnet_lora/lora/`

---

## 5. æ—©åœä¸æ¢¯åº¦ç´¯è®¡ï¼ˆå¼ºçƒˆæ¨èï¼‰

- æ¢¯åº¦ç´¯è®¡
  - é€šè¿‡é…ç½® `training.gradient_accumulation_steps` è®¾ç½®ï¼ˆLoRA ä¸è”åˆè„šæœ¬å‡å·²å†…ç½®ï¼Œä½¿ç”¨ accelerate ç®¡ç†ï¼‰ï¼›æœ‰æ•ˆ batch = `train_batch_size Ã— gradient_accumulation_steps`
- æ—©åœï¼ˆé˜²æ­¢è¿‡è®­ã€èŠ‚çœæ—¶é—´ï¼‰
  - åœ¨é…ç½®ä¸­å¼€å¯ï¼š
    ```yaml
    early_stopping:
      enabled: true
      patience: 5        # è¿ç»­è‹¥å¹² epoch æ— æ˜æ˜¾æ”¹è¿›åˆ™åœæ­¢
      min_delta: 0.0     # è®¤ä¸ºâ€œæœ‰æ”¹è¿›â€çš„æœ€å°å¹…åº¦
    ```
  - ç›‘æ§æŒ‡æ ‡ä¸º `weighted_loss_epoch`ï¼ˆè®­ç»ƒé›†å‡å€¼ï¼‰ã€‚å¦‚éœ€æ›´ä¸¥æ ¼ï¼Œå¯æ›¿æ¢ä¸ºéªŒè¯é›†æŒ‡æ ‡ï¼ˆå¯æ‰©å±•ï¼‰ã€‚

---

## 6. å°è´´å£«ï¼ˆç”»è´¨ä¸ç²¾åº¦å…¼é¡¾ï¼‰
- ä½ç½®å·²ç¨³æ—¶ï¼ŒLoRA ä¸»è¦æå‡ç”»è´¨ï¼›è‹¥å®šä½è½»å¾®å—å½±å“ï¼Œé™ä½ `lora_scale`ï¼ˆå¦‚ 0.5â€“0.6ï¼‰ã€‚
- è®­ç»ƒ/æ¨ç†çš„ `sigma` è¦ä¸€è‡´ï¼ˆå»ºè®® 8.0ï¼‰ã€‚
- æ¨ç†å»ºè®®ï¼šsteps 30â€“50ã€CFG 3â€“5ã€controlnet_conditioning_scale 1.0â€“1.3ã€‚

---

## 7. äº§ç‰©ä¸æ—¥å¿—ä½ç½®
- ControlNet æœ€ç»ˆæ¨¡å‹ï¼š`output/controlnet/controlnet/`
- LoRA æœ€ç»ˆæƒé‡ï¼š`output/controlnet_lora/lora/`
- æ—¥å¿—ï¼šå„è‡ªç›®å½•ä¸‹ `logs/`

ç¥è®­ç»ƒé¡ºåˆ©ï¼Œç”»è´¨ä¸ç²¾åº¦åŒèµ¢ï¼
